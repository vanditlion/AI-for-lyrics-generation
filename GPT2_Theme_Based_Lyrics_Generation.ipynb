{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdpEgaDmizaC","outputId":"ee170d65-1ccc-4c68-b996-18d706821e74"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.9.1)\n","Requirement already satisfied: rouge in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n","Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (4.67.1)\n","Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rouge) (1.16.0)\n"]}],"source":["# Installing necessary packages\n","!pip install nltk rouge"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPPVNaA5FPe1","outputId":"4ebf59d3-dac9-42b7-d1d0-b604997d4175"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[nltk_data] Downloading package punkt to /Users/Ayush/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# Importing necessary packages and libraries\n","import os\n","import pandas as pd\n","import random\n","import torch\n","import nltk\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from rouge import Rouge\n","\n","# Handle SSL issue for NLTK punkt download\n","import ssl\n","try:\n","    _create_default_https_context = ssl._create_default_https_context\n","    ssl._create_default_https_context = ssl._create_unverified_context\n","    nltk.download('punkt')\n","finally:\n","    ssl._create_default_https_context = _create_default_https_context\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3701jwYq7HYS","outputId":"40e0080c-68f9-4836-ab13-1bf646e4604d"},"outputs":[],"source":["# # Mounting Google Drive in Google Colab\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ZOwdTR247YGy"},"outputs":[],"source":["# Listing all available artists based on filenames in a directory\n","def list_available_artists(directory):\n","    files = os.listdir(directory)\n","    print(files)\n","    artists = [file.split('_')[-1].replace('.csv', '') for file in files if file.startswith('processed_LDA_lyrics_with_topic_')]\n","    return artists\n","\n","# artists = list_available_artists('/Users/Ayush/MLProject/ML FINAL PROJECT')\n","# print(artists)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"OrDtvets8j6G"},"outputs":[],"source":["# Loading lyrics data for a specific artist and theme\n","def load_lyrics(artist_name, theme, directory):\n","    file_path = os.path.join(directory, f'processed_LDA_lyrics_with_topic_{artist_name}.csv')\n","    if not os.path.exists(file_path):\n","        return None\n","    df = pd.read_csv(file_path)\n","    return df[df['theme'] == theme]['processed_lyrics'].tolist()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Loading themes for a given artist\n","def load_themes(artist_name, directory):\n","    file_path = os.path.join(directory, f'processed_LDA_lyrics_with_topic_{artist_name}.csv')\n","    if not os.path.exists(file_path):\n","        return None\n","    df = pd.read_csv(file_path)\n","    return df['theme'].unique()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"sxWox78F8nLP"},"outputs":[],"source":["# Generating lyrics in structured format\n","def generate_lyrics(model, tokenizer, lyrics, seed_text, max_length=100, device='cpu'):\n","    model.eval()\n","    context_line = random.choice(lyrics)  # Adding context from existing lyrics\n","    input_ids = tokenizer.encode(f\"{seed_text} {context_line}\", return_tensors='pt').to(device)\n","    sample_outputs = model.generate(\n","        input_ids,\n","        max_length=max_length + len(input_ids[0]),\n","        pad_token_id=tokenizer.eos_token_id,\n","        do_sample=True,\n","        top_k=50,\n","        top_p=0.90,\n","        temperature=0.8,\n","        no_repeat_ngram_size=2,\n","        repetition_penalty=1.5\n","    )\n","    # Decoding and formating the output\n","    generated_text = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n","    # Limiting the output to 100 words\n","    words = generated_text.split()[:100]\n","    return ' '.join(words)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"EHsS5O678oH7"},"outputs":[],"source":["# Additional formatting to introduce rhyme and structure\n","def format_lyrics_improved(lyrics):\n","    lines = lyrics.split('. ')\n","    formatted_lyrics = \"\\n\".join(line.capitalize() for line in lines if line)\n","    return formatted_lyrics"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"emGVexwM8qxi"},"outputs":[],"source":["# Calculating BLEU score with smoothing.\n","def calculate_bleu(reference_words, generated_words):\n","    smoothie = SmoothingFunction().method4\n","    bleu_score = sentence_bleu(reference_words, generated_words, smoothing_function=smoothie)\n","    return bleu_score"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"sunLr8ZB8zI8"},"outputs":[],"source":["# Defining and calling function to generate appropriate lyrics matching the esseance of artist and its theme provided by the user\n","def main():\n","    directory = '/Users/Ayush/MLProject/data'\n","    # Reading name of the artist from the available list\n","    artists = list_available_artists(directory)\n","    print(\"Available artists:\", artists)\n","    artist_name = input(\"Enter an artist from the list: \")\n","    if artist_name not in artists:\n","        print(\"Artist not available. Please choose from the list.\")\n","        return\n","    # Providing list of unique themes of the selected artist\n","    themes = load_themes(artist_name, directory)\n","    if themes is None:\n","        print(\"No themes available for the selected artist.\")\n","        return\n","    # Reading theme provided by the user based on the list\n","    print(\"Available themes:\", themes)\n","    theme = input(\"Select a theme from the list: \")\n","    if theme not in themes:\n","        print(\"Theme not available. Please choose from the list.\")\n","        return\n","    # Reading seed text which act as starting part of the lyrics\n","    seed_text = input(\"Enter a seed phrase to start the lyrics: \")\n","    lyrics = load_lyrics(artist_name, theme, directory)\n","    if lyrics is None:\n","        print(\"No lyrics data found for the selected theme.\")\n","        return\n","    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","    model = GPT2LMHeadModel.from_pretrained('gpt2')\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.to(device)\n","    # Generating lyrics in proper format\n","    generated_lyrics = generate_lyrics(model, tokenizer, lyrics, seed_text, device=device)\n","    formatted_lyrics = format_lyrics_improved(generated_lyrics)\n","    print(\"Generated Lyrics:\\n\", formatted_lyrics)\n","    # Evaluating the lyrics using the BLEU and Rouge calculation\n","    reference_data = lyrics[int(len(lyrics) * 0.8):]\n","    generated_words = formatted_lyrics.split()\n","    reference_words = [ref.split() for ref in reference_data]\n","    bleu_score = calculate_bleu(reference_words, generated_words)\n","    print(f\"BLEU Score: {bleu_score}\")\n","    rouge = Rouge()\n","    try:\n","        rouge_scores = rouge.get_scores(' '.join(generated_words), ' '.join(reference_words[0]))\n","        print(\"ROUGE Scores:\", rouge_scores)\n","    except IndexError:\n","        print(\"ROUGE Scores: Not enough reference data to evaluate ROUGE.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7ooLRnk-Hmo","outputId":"732ec9cf-c8d2-45d3-ec8b-40ac2e72f069"},"outputs":[{"name":"stdout","output_type":"stream","text":["['processed_LDA_lyrics_with_topic_arctic monkeys.csv', 'processed_LDA_lyrics_with_topic_drake.csv', 'processed_LDA_lyrics_with_topic_post malone.csv', 'processed_LDA_lyrics_with_topic_halsey.csv', 'processed_LDA_lyrics_with_topic_imagine dragons.csv', 'processed_LDA_lyrics_with_topic_eminem.csv', 'processed_LDA_lyrics_with_topic_lady gaga.csv', 'processed_LDA_lyrics_with_topic_pink floyd.csv', 'processed_LDA_lyrics_with_topic_machine gun kelly.csv', 'processed_LDA_lyrics_with_topic_dj khaled.csv', 'processed_LDA_lyrics_with_topic_nirvana.csv', 'processed_LDA_lyrics_with_topic_travis scott.csv', 'processed_LDA_lyrics_with_topic_ariana grande.csv', 'processed_LDA_lyrics_with_topic_ed sheeran.csv', 'processed_LDA_lyrics_with_topic_maroon 5.csv', 'processed_LDA_lyrics_with_topic_justin bieber.csv', 'processed_LDA_lyrics_with_topic_taylor swift.csv', 'processed_LDA_lyrics_with_topic_cardi b.csv', 'processed_LDA_lyrics_with_topic_billie eilish.csv', 'processed_LDA_lyrics_with_topic_queen.csv', 'processed_LDA_lyrics_with_topic_21 savage.csv', 'processed_LDA_lyrics_with_topic_the beatles.csv']\n","Available artists: ['arctic monkeys', 'drake', 'post malone', 'halsey', 'imagine dragons', 'eminem', 'lady gaga', 'pink floyd', 'machine gun kelly', 'dj khaled', 'nirvana', 'travis scott', 'ariana grande', 'ed sheeran', 'maroon 5', 'justin bieber', 'taylor swift', 'cardi b', 'billie eilish', 'queen', '21 savage', 'the beatles']\n","Available themes: ['Emotional Connections' 'Identity & Recognition' 'Life & Aspirations']\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"name":"stdout","output_type":"stream","text":["Generated Lyrics:\n"," Identity & recognition oliver set safe - eternity safe - nuh time safe - don't lie puffy l'z and mo-g â€“ switch it up anthem yg - i wanna benz ft \n","50 cent and nipsey hu$$le offset - first day out rich the kid - that bag young thug - hercules cashier fresh - before lil wayne - jumpman starlito - yaomingolajuwon a$ap rocky - wavybone ft \n","Juicy j and ugk prince 85 set raf riley - summer ft \n","Etta bond , avelino and dun d aaliyah - we need a resolution young thug - paradise michael\n","BLEU Score: 0.018717746813977667\n","ROUGE Scores: [{'rouge-1': {'r': 0.060836501901140684, 'p': 0.21621621621621623, 'f': 0.09495548618689971}, 'rouge-2': {'r': 0.0064516129032258064, 'p': 0.03260869565217391, 'f': 0.010771990060887282}, 'rouge-l': {'r': 0.049429657794676805, 'p': 0.17567567567567569, 'f': 0.07715133188422912}}]\n"]}],"source":["# Calling main function to perform all the operations and generating appropriate lyrics\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeUA89r9bp2Q","outputId":"f99671be-6016-4492-9909-94063a23c334"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT2Config {\n","  \"_attn_implementation_autoset\": true,\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.46.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}],"source":["from transformers import GPT2Model, GPT2Config\n","# Load pre-configured GPT-2\n","config = GPT2Config()\n","model = GPT2Model(config)\n","# Print the model's configuration\n","print(model.config)"]},{"cell_type":"markdown","metadata":{"id":"S5Dw1INYmAZP"},"source":["## Hyperparameter Table\n","\n","| Hyperparameter Name         | Value                            |\n","|-----------------------------|----------------------------------|\n","| Activation Function (Hidden Layer) | GeLU                       |\n","| Activation Function (Output Layer) | Linear                     |\n","| Weight Initializer          | Normal Distribution (std=0.02)  |\n","| Number of Hidden Layers     | 12                              |\n","| Neurons in Hidden Layers    | 768                             |\n","| Loss Function               | Categorical Cross-Entropy               |\n","| Optimizer                   | AdamW                            |\n","| Number of Epochs            | 3                               |\n","| Batch Size                  | 32                              |\n","| Learning Rate               | 5e-5                            |\n","| Evaluation Metric           | Bleu, Rouge                      |\n","| Dropout Rate                | 0.1                             ||"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
